{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXx7cpBpZXaG"
   },
   "outputs": [],
   "source": [
    "#추진방법\n",
    "##이미지, 영상에서 사람얼굴 식별(Opencv, Haar-Cascade-Classifiers, 딥러닝 등)\n",
    "##블러처리 하여 export\n",
    "##향후 streamlit, bootstrap 등으로 웹으로 시각화하여 구축\n",
    "##최종적으로 이미지, 영상 업로드하여 가명처리된 이미지, 영상 export 설계\n",
    "##영상 처리시 속도가 너무 느림, 경량화하는 방법 필요\n",
    "\n",
    "#참고문헌\n",
    "## https://velog.io/@smile_b/Haar-Cascade-Classifiers%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%96%BC%EA%B5%B4-%EB%B0%8F-%EB%88%88-%EA%B0%90%EC%A7%80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3bMOWK0XrwL",
    "outputId": "e8f60fbf-b938-4706-f3b1-aaa12021f968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/38.8 MB 11.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.0/38.8 MB 11.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.3/38.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.0/38.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.6/38.8 MB 11.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.9/38.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 17.6/38.8 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.2/38.8 MB 11.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.5/38.8 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/38.8 MB 11.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/38.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.4/38.8 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.8/38.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 11.4 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "#오픈 CV 설치\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n70XgT4dbnB_",
    "outputId": "c47085f9-fc07-4adf-e119-e4cc0e4660ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  sample.mp4\n"
     ]
    }
   ],
   "source": [
    "#현재 경로파악\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNNjsR8HcTsv"
   },
   "outputs": [],
   "source": [
    "#1. 영상 가명처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGYW8KsKX22Q",
    "outputId": "e5dd1dc6-f841-461d-8645-2b30e1d23a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률: 0.83% | 남은 시간: 180.58초\n",
      "진행률: 1.67% | 남은 시간: 173.28초\n",
      "진행률: 2.50% | 남은 시간: 173.79초\n",
      "진행률: 3.34% | 남은 시간: 191.96초\n",
      "진행률: 4.17% | 남은 시간: 189.88초\n",
      "진행률: 5.01% | 남은 시간: 183.82초\n",
      "진행률: 5.84% | 남은 시간: 178.99초\n",
      "진행률: 6.68% | 남은 시간: 175.53초\n",
      "진행률: 7.51% | 남은 시간: 172.33초\n",
      "진행률: 8.35% | 남은 시간: 169.83초\n",
      "진행률: 9.18% | 남은 시간: 167.49초\n",
      "진행률: 10.02% | 남은 시간: 170.87초\n",
      "진행률: 10.85% | 남은 시간: 173.59초\n",
      "진행률: 11.69% | 남은 시간: 170.91초\n",
      "진행률: 12.52% | 남은 시간: 168.36초\n",
      "진행률: 13.36% | 남은 시간: 165.86초\n",
      "진행률: 14.19% | 남은 시간: 163.71초\n",
      "진행률: 15.03% | 남은 시간: 161.45초\n",
      "진행률: 15.86% | 남은 시간: 159.70초\n",
      "진행률: 16.69% | 남은 시간: 159.93초\n",
      "진행률: 17.53% | 남은 시간: 161.32초\n",
      "진행률: 18.36% | 남은 시간: 159.06초\n",
      "진행률: 19.20% | 남은 시간: 156.88초\n",
      "진행률: 20.03% | 남은 시간: 154.66초\n",
      "진행률: 20.87% | 남은 시간: 152.86초\n",
      "진행률: 21.70% | 남은 시간: 150.02초\n",
      "진행률: 22.54% | 남은 시간: 146.69초\n",
      "진행률: 23.37% | 남은 시간: 143.40초\n",
      "진행률: 24.21% | 남은 시간: 141.81초\n",
      "진행률: 25.04% | 남은 시간: 140.83초\n",
      "진행률: 25.88% | 남은 시간: 137.90초\n",
      "진행률: 26.71% | 남은 시간: 135.06초\n",
      "진행률: 27.55% | 남은 시간: 132.78초\n",
      "진행률: 28.38% | 남은 시간: 130.77초\n",
      "진행률: 29.22% | 남은 시간: 128.16초\n",
      "진행률: 30.05% | 남은 시간: 125.61초\n",
      "진행률: 30.88% | 남은 시간: 123.17초\n",
      "진행률: 31.72% | 남은 시간: 120.85초\n",
      "진행률: 32.55% | 남은 시간: 118.89초\n",
      "진행률: 33.39% | 남은 시간: 118.12초\n",
      "진행률: 34.22% | 남은 시간: 116.52초\n",
      "진행률: 35.06% | 남은 시간: 114.36초\n",
      "진행률: 35.89% | 남은 시간: 112.35초\n",
      "진행률: 36.73% | 남은 시간: 110.59초\n",
      "진행률: 37.56% | 남은 시간: 108.84초\n",
      "진행률: 38.40% | 남은 시간: 107.03초\n",
      "진행률: 39.23% | 남은 시간: 105.18초\n",
      "진행률: 40.07% | 남은 시간: 103.37초\n",
      "진행률: 40.90% | 남은 시간: 101.86초\n",
      "진행률: 41.74% | 남은 시간: 101.26초\n",
      "진행률: 42.57% | 남은 시간: 99.82초\n",
      "진행률: 43.41% | 남은 시간: 98.03초\n",
      "진행률: 44.24% | 남은 시간: 96.27초\n",
      "진행률: 45.08% | 남은 시간: 94.52초\n",
      "진행률: 45.91% | 남은 시간: 92.80초\n",
      "진행률: 46.74% | 남은 시간: 91.08초\n",
      "진행률: 47.58% | 남은 시간: 89.41초\n",
      "진행률: 48.41% | 남은 시간: 87.75초\n",
      "진행률: 49.25% | 남은 시간: 86.21초\n",
      "진행률: 50.08% | 남은 시간: 85.22초\n",
      "진행률: 50.92% | 남은 시간: 83.81초\n",
      "진행률: 51.75% | 남은 시간: 82.05초\n",
      "진행률: 52.59% | 남은 시간: 80.29초\n",
      "진행률: 53.42% | 남은 시간: 78.60초\n",
      "진행률: 54.26% | 남은 시간: 76.92초\n",
      "진행률: 55.09% | 남은 시간: 75.29초\n",
      "진행률: 55.93% | 남은 시간: 73.64초\n",
      "진행률: 56.76% | 남은 시간: 72.00초\n",
      "진행률: 57.60% | 남은 시간: 70.39초\n",
      "진행률: 58.43% | 남은 시간: 68.96초\n",
      "진행률: 59.27% | 남은 시간: 67.91초\n",
      "진행률: 60.10% | 남은 시간: 66.56초\n",
      "진행률: 60.93% | 남은 시간: 65.00초\n",
      "진행률: 61.77% | 남은 시간: 63.51초\n",
      "진행률: 62.60% | 남은 시간: 62.00초\n",
      "진행률: 63.44% | 남은 시간: 60.40초\n",
      "진행률: 64.27% | 남은 시간: 58.84초\n",
      "진행률: 65.11% | 남은 시간: 57.29초\n",
      "진행률: 65.94% | 남은 시간: 55.75초\n",
      "진행률: 66.78% | 남은 시간: 54.19초\n",
      "진행률: 67.61% | 남은 시간: 52.67초\n",
      "진행률: 68.45% | 남은 시간: 51.41초\n",
      "진행률: 69.28% | 남은 시간: 50.11초\n",
      "진행률: 70.12% | 남은 시간: 48.58초\n",
      "진행률: 70.95% | 남은 시간: 47.07초\n",
      "진행률: 71.79% | 남은 시간: 45.56초\n",
      "진행률: 72.62% | 남은 시간: 44.07초\n",
      "진행률: 73.46% | 남은 시간: 42.59초\n",
      "진행률: 74.29% | 남은 시간: 41.12초\n",
      "진행률: 75.13% | 남은 시간: 39.66초\n",
      "진행률: 75.96% | 남은 시간: 38.22초\n",
      "진행률: 76.79% | 남은 시간: 36.78초\n",
      "진행률: 77.63% | 남은 시간: 35.37초\n",
      "진행률: 78.46% | 남은 시간: 34.12초\n",
      "진행률: 79.30% | 남은 시간: 32.84초\n",
      "진행률: 80.13% | 남은 시간: 31.44초\n",
      "진행률: 80.97% | 남은 시간: 30.05초\n",
      "진행률: 81.80% | 남은 시간: 28.67초\n",
      "진행률: 82.64% | 남은 시간: 27.30초\n",
      "진행률: 83.47% | 남은 시간: 25.94초\n",
      "진행률: 84.31% | 남은 시간: 24.58초\n",
      "진행률: 85.14% | 남은 시간: 23.24초\n",
      "진행률: 85.98% | 남은 시간: 21.90초\n",
      "진행률: 86.81% | 남은 시간: 20.55초\n",
      "진행률: 87.65% | 남은 시간: 19.27초\n",
      "진행률: 88.48% | 남은 시간: 18.02초\n",
      "진행률: 89.32% | 남은 시간: 16.69초\n",
      "진행률: 90.15% | 남은 시간: 15.35초\n",
      "진행률: 90.98% | 남은 시간: 14.03초\n",
      "진행률: 91.82% | 남은 시간: 12.70초\n",
      "진행률: 92.65% | 남은 시간: 11.39초\n",
      "진행률: 93.49% | 남은 시간: 10.07초\n",
      "진행률: 94.32% | 남은 시간: 8.76초\n",
      "진행률: 95.16% | 남은 시간: 7.45초\n",
      "진행률: 95.99% | 남은 시간: 6.16초\n",
      "진행률: 96.83% | 남은 시간: 4.86초\n",
      "진행률: 97.66% | 남은 시간: 3.59초\n",
      "진행률: 98.50% | 남은 시간: 2.31초\n",
      "진행률: 99.33% | 남은 시간: 1.02초\n",
      "가명처리된 동영상이 저장되었습니다: /content/sample_data/blurred_output.mp4\n",
      "총 처리 시간: 153.26초\n"
     ]
    }
   ],
   "source": [
    "#1. Haar Cascade 적용(정면 이미지 잘됨, 측면 얼굴 잘안됨)\n",
    "\n",
    "# 동영상 파일 경로\n",
    "input_video_path = '/content/sample_data/sample.mp4'\n",
    "output_video_path = '/content/sample_data/blurred_output.mp4'\n",
    "\n",
    "#라이브러리 로드\n",
    "import cv2\n",
    "import time\n",
    "# 얼굴 인식을 위한 Haar Cascade XML 파일 로드\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 동영상의 속성 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# 비디오 저장 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# 시간 측정 시작\n",
    "start_time = time.time()\n",
    "\n",
    "# 프레임 처리 설정\n",
    "frame_skip = 5  # 5 프레임마다 얼굴 탐지 수행\n",
    "frame_count = 0\n",
    "faces = []  # 이전 프레임의 얼굴 위치 저장\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 일정 간격마다 얼굴 재탐지 수행\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # 그레이스케일로 변환 (얼굴 인식을 위해)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        detected_faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,  # 정확도를 높이기 위해 scaleFactor를 약간 높임\n",
    "            minNeighbors=7,   # 인접한 네이버 수 증가\n",
    "            minSize=(40, 40)  # 최소 얼굴 크기 제한 (작은 객체 인식 방지)\n",
    "        )\n",
    "\n",
    "        # 신뢰도 기준으로 잘못된 인식을 필터링\n",
    "        faces = []\n",
    "        for (x, y, w, h) in detected_faces:\n",
    "            # 얼굴 크기 비율 검증 (너무 작거나 너무 큰 객체 필터링)\n",
    "            if w > 50 and h > 50 and w/h < 1.5 and h/w < 1.5:\n",
    "                faces.append((x, y, w, h))\n",
    "\n",
    "    # 얼굴 부분 블러 처리\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        blurred_face = cv2.GaussianBlur(face, (30, 30), 30)\n",
    "        frame[y:y+h, x:x+w] = blurred_face\n",
    "\n",
    "    # 결과 프레임을 출력 파일에 저장\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # 남은 시간 예측\n",
    "    if frame_count % 10 == 0:  # 매 10 프레임마다 남은 시간 업데이트\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_total_time = (elapsed_time / frame_count) * total_frames\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "        print(f\"진행률: {frame_count / total_frames * 100:.2f}% | 남은 시간: {remaining_time:.2f}초\")\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 총 처리 시간\n",
    "end_time = time.time()\n",
    "total_elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"가명처리된 동영상이 저장되었습니다:\", output_video_path)\n",
    "print(f\"총 처리 시간: {total_elapsed_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SOybl8WffnP",
    "outputId": "787a7108-0c4b-4802-ccb1-488e7e03ecd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from facenet-pytorch) (4.66.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\torch_gpu\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#1-2 MTCNN(Multi-task Cascaded Convolutional Networks)이나 Dlib의 얼굴 인식 모델 활용\n",
    "#1-1보다 성능 개선 이루어짐\n",
    "\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AM4cJB_CfabA",
    "outputId": "b0ec0294-a8dc-486d-80a3-55a230a9b975"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\torch_GPU\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률: 0.83% | 남은 시간: 879.15초\n",
      "진행률: 1.67% | 남은 시간: 575.47초\n",
      "진행률: 2.50% | 남은 시간: 471.67초\n",
      "진행률: 3.34% | 남은 시간: 419.75초\n",
      "진행률: 4.17% | 남은 시간: 388.60초\n",
      "진행률: 5.01% | 남은 시간: 365.78초\n",
      "진행률: 5.84% | 남은 시간: 349.11초\n",
      "진행률: 6.68% | 남은 시간: 336.43초\n",
      "진행률: 7.51% | 남은 시간: 325.81초\n",
      "진행률: 8.35% | 남은 시간: 318.00초\n",
      "진행률: 9.18% | 남은 시간: 309.97초\n",
      "진행률: 10.02% | 남은 시간: 303.04초\n",
      "진행률: 10.85% | 남은 시간: 297.06초\n",
      "진행률: 11.69% | 남은 시간: 291.41초\n",
      "진행률: 12.52% | 남은 시간: 286.55초\n",
      "진행률: 13.36% | 남은 시간: 281.66초\n",
      "진행률: 14.19% | 남은 시간: 277.31초\n",
      "진행률: 15.03% | 남은 시간: 273.26초\n",
      "진행률: 15.86% | 남은 시간: 269.63초\n",
      "진행률: 16.69% | 남은 시간: 265.69초\n",
      "진행률: 17.53% | 남은 시간: 262.34초\n",
      "진행률: 18.36% | 남은 시간: 258.86초\n",
      "진행률: 19.20% | 남은 시간: 255.62초\n",
      "진행률: 20.03% | 남은 시간: 252.48초\n",
      "진행률: 20.87% | 남은 시간: 249.35초\n",
      "진행률: 21.70% | 남은 시간: 245.10초\n",
      "진행률: 22.54% | 남은 시간: 239.81초\n",
      "진행률: 23.37% | 남은 시간: 234.57초\n",
      "진행률: 24.21% | 남은 시간: 229.62초\n",
      "진행률: 25.04% | 남은 시간: 224.91초\n",
      "진행률: 25.88% | 남은 시간: 220.49초\n",
      "진행률: 26.71% | 남은 시간: 216.10초\n",
      "진행률: 27.55% | 남은 시간: 211.93초\n",
      "진행률: 28.38% | 남은 시간: 207.88초\n",
      "진행률: 29.22% | 남은 시간: 204.00초\n",
      "진행률: 30.05% | 남은 시간: 200.26초\n",
      "진행률: 30.88% | 남은 시간: 196.55초\n",
      "진행률: 31.72% | 남은 시간: 192.92초\n",
      "진행률: 32.55% | 남은 시간: 189.42초\n",
      "진행률: 33.39% | 남은 시간: 186.04초\n",
      "진행률: 34.22% | 남은 시간: 182.79초\n",
      "진행률: 35.06% | 남은 시간: 179.70초\n",
      "진행률: 35.89% | 남은 시간: 177.00초\n",
      "진행률: 36.73% | 남은 시간: 175.98초\n",
      "진행률: 37.56% | 남은 시간: 174.93초\n",
      "진행률: 38.40% | 남은 시간: 172.73초\n",
      "진행률: 39.23% | 남은 시간: 170.18초\n",
      "진행률: 40.07% | 남은 시간: 167.63초\n",
      "진행률: 40.90% | 남은 시간: 165.06초\n",
      "진행률: 41.74% | 남은 시간: 162.52초\n",
      "진행률: 42.57% | 남은 시간: 159.86초\n",
      "진행률: 43.41% | 남은 시간: 157.31초\n",
      "진행률: 44.24% | 남은 시간: 154.76초\n",
      "진행률: 45.08% | 남은 시간: 152.20초\n",
      "진행률: 45.91% | 남은 시간: 149.71초\n",
      "진행률: 46.74% | 남은 시간: 147.09초\n",
      "진행률: 47.58% | 남은 시간: 144.53초\n",
      "진행률: 48.41% | 남은 시간: 141.91초\n",
      "진행률: 49.25% | 남은 시간: 139.34초\n",
      "진행률: 50.08% | 남은 시간: 136.84초\n",
      "진행률: 50.92% | 남은 시간: 134.22초\n",
      "진행률: 51.75% | 남은 시간: 131.49초\n",
      "진행률: 52.59% | 남은 시간: 128.78초\n",
      "진행률: 53.42% | 남은 시간: 126.12초\n",
      "진행률: 54.26% | 남은 시간: 123.46초\n",
      "진행률: 55.09% | 남은 시간: 120.86초\n",
      "진행률: 55.93% | 남은 시간: 118.29초\n",
      "진행률: 56.76% | 남은 시간: 115.77초\n",
      "진행률: 57.60% | 남은 시간: 113.32초\n",
      "진행률: 58.43% | 남은 시간: 110.82초\n",
      "진행률: 59.27% | 남은 시간: 108.38초\n",
      "진행률: 60.10% | 남은 시간: 105.92초\n",
      "진행률: 60.93% | 남은 시간: 103.48초\n",
      "진행률: 61.77% | 남은 시간: 101.04초\n",
      "진행률: 62.60% | 남은 시간: 98.87초\n",
      "진행률: 63.44% | 남은 시간: 96.78초\n",
      "진행률: 64.27% | 남은 시간: 94.72초\n",
      "진행률: 65.11% | 남은 시간: 92.63초\n",
      "진행률: 65.94% | 남은 시간: 90.53초\n",
      "진행률: 66.78% | 남은 시간: 88.42초\n",
      "진행률: 67.61% | 남은 시간: 86.33초\n",
      "진행률: 68.45% | 남은 시간: 84.22초\n",
      "진행률: 69.28% | 남은 시간: 82.12초\n",
      "진행률: 70.12% | 남은 시간: 80.00초\n",
      "진행률: 70.95% | 남은 시간: 77.86초\n",
      "진행률: 71.79% | 남은 시간: 75.71초\n",
      "진행률: 72.62% | 남은 시간: 73.57초\n",
      "진행률: 73.46% | 남은 시간: 71.40초\n",
      "진행률: 74.29% | 남은 시간: 69.23초\n",
      "진행률: 75.13% | 남은 시간: 67.07초\n",
      "진행률: 75.96% | 남은 시간: 64.87초\n",
      "진행률: 76.79% | 남은 시간: 62.68초\n",
      "진행률: 77.63% | 남은 시간: 60.50초\n",
      "진행률: 78.46% | 남은 시간: 58.30초\n",
      "진행률: 79.30% | 남은 시간: 56.08초\n",
      "진행률: 80.13% | 남은 시간: 53.81초\n",
      "진행률: 80.97% | 남은 시간: 51.55초\n",
      "진행률: 81.80% | 남은 시간: 49.28초\n",
      "진행률: 82.64% | 남은 시간: 47.00초\n",
      "진행률: 83.47% | 남은 시간: 44.74초\n",
      "진행률: 84.31% | 남은 시간: 42.48초\n",
      "진행률: 85.14% | 남은 시간: 40.22초\n",
      "진행률: 85.98% | 남은 시간: 37.94초\n",
      "진행률: 86.81% | 남은 시간: 35.67초\n",
      "진행률: 87.65% | 남은 시간: 33.39초\n",
      "진행률: 88.48% | 남은 시간: 31.11초\n",
      "진행률: 89.32% | 남은 시간: 28.84초\n",
      "진행률: 90.15% | 남은 시간: 26.56초\n",
      "진행률: 90.98% | 남은 시간: 24.29초\n",
      "진행률: 91.82% | 남은 시간: 22.02초\n",
      "진행률: 92.65% | 남은 시간: 19.75초\n",
      "진행률: 93.49% | 남은 시간: 17.48초\n",
      "진행률: 94.32% | 남은 시간: 15.25초\n",
      "진행률: 95.16% | 남은 시간: 12.99초\n",
      "진행률: 95.99% | 남은 시간: 10.74초\n",
      "진행률: 96.83% | 남은 시간: 8.49초\n",
      "진행률: 97.66% | 남은 시간: 6.25초\n",
      "진행률: 98.50% | 남은 시간: 4.01초\n",
      "진행률: 99.33% | 남은 시간: 1.78초\n",
      "가명처리된 동영상이 저장되었습니다: sample_data/blurred_output.mp4\n",
      "총 처리 시간: 266.24초\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_video_path = 'sample_data/sample.mp4'\n",
    "output_video_path = 'sample_data/blurred_output.mp4'\n",
    "\n",
    "# MTCNN 모델 초기화 (GPU가 있다면 device='cuda'로 설정 가능) #cpu 1900초, gpu 400초 소요(1/5 시간감축)\n",
    "mtcnn = MTCNN(keep_all=True, device='cuda')\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 동영상의 속성 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# 비디오 저장 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# 시간 측정 시작\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # PIL 형식으로 변환 (MTCNN은 PIL 이미지를 입력으로 받음)\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # 얼굴 인식\n",
    "    boxes, _ = mtcnn.detect(frame_pil)\n",
    "\n",
    "    # 얼굴 부분 블러 처리\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "            blurred_face = cv2.GaussianBlur(face, (31, 31), 30)  # 커널 크기 조정 (30, 30로 설정)\n",
    "            frame[y1:y2, x1:x2] = blurred_face\n",
    "\n",
    "    # 결과 프레임을 출력 파일에 저장\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # 남은 시간 예측\n",
    "    if frame_count % 10 == 0:  # 매 10 프레임마다 남은 시간 업데이트\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_total_time = (elapsed_time / frame_count) * total_frames\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "        print(f\"진행률: {frame_count / total_frames * 100:.2f}% | 남은 시간: {remaining_time:.2f}초\")\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 총 처리 시간\n",
    "end_time = time.time()\n",
    "total_elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"가명처리된 동영상이 저장되었습니다:\", output_video_path)\n",
    "print(f\"총 처리 시간: {total_elapsed_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lrNUd3ykVsI",
    "outputId": "b8a7d1bc-aef6-4057-c7ba-ed343e0489d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.27-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.27-py3-none-any.whl (878 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.27 ultralytics-thop-2.0.10\n"
     ]
    }
   ],
   "source": [
    "#1-3 가장 최근에 나온 YOLOv8-Face로 활용\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovpwy4dblhUB",
    "outputId": "c2700b70-f2aa-4dc4-866a-850bdf490cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-03 05:54:47--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241103T055447Z&X-Amz-Expires=300&X-Amz-Signature=a3b77f24d508c676ab5ff8984a89f6d51d248a5a476b0574ee478c3957f10fc3&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-11-03 05:54:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241103T055447Z&X-Amz-Expires=300&X-Amz-Signature=a3b77f24d508c676ab5ff8984a89f6d51d248a5a476b0574ee478c3957f10fc3&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6534387 (6.2M) [application/octet-stream]\n",
      "Saving to: ‘/content/weights/yolov8n.pt’\n",
      "\n",
      "/content/weights/yo 100%[===================>]   6.23M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-11-03 05:54:48 (158 MB/s) - ‘/content/weights/yolov8n.pt’ saved [6534387/6534387]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/weights\n",
    "!wget -O /content/weights/yolov8n.pt https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQbkq_VZkVup",
    "outputId": "e5e675b3-0d80-4c75-acae-25b603a36c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 127.9ms\n",
      "Speed: 12.7ms preprocess, 127.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.9ms\n",
      "Speed: 3.7ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 0.83% | 남은 시간: 124.10초\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 3.8ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.6ms\n",
      "Speed: 3.4ms preprocess, 18.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 1.67% | 남은 시간: 90.47초\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 3.5ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 2.50% | 남은 시간: 72.21초\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 3.34% | 남은 시간: 62.48초\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 3.3ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 4.17% | 남은 시간: 56.66초\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 5.5ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 2.9ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 5.01% | 남은 시간: 52.82초\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 5.84% | 남은 시간: 49.79초\n",
      "\n",
      "0: 384x640 (no detections), 11.4ms\n",
      "Speed: 4.0ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 4.9ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 6.68% | 남은 시간: 47.69초\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 3.5ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 17.8ms\n",
      "Speed: 6.3ms preprocess, 17.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 7.51% | 남은 시간: 46.57초\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 4.2ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.6ms\n",
      "Speed: 3.6ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 8.35% | 남은 시간: 45.92초\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 3.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 9.18% | 남은 시간: 45.25초\n",
      "\n",
      "0: 384x640 (no detections), 14.7ms\n",
      "Speed: 3.4ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.9ms\n",
      "Speed: 3.5ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 10.02% | 남은 시간: 44.36초\n",
      "\n",
      "0: 384x640 (no detections), 14.2ms\n",
      "Speed: 3.4ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 3.7ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 10.85% | 남은 시간: 43.45초\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 11.69% | 남은 시간: 43.05초\n",
      "\n",
      "0: 384x640 (no detections), 17.0ms\n",
      "Speed: 3.3ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 3.7ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 12.52% | 남은 시간: 42.31초\n",
      "\n",
      "0: 384x640 (no detections), 19.2ms\n",
      "Speed: 3.5ms preprocess, 19.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 3.6ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 13.36% | 남은 시간: 41.70초\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 4.1ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.1ms\n",
      "Speed: 4.3ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 14.19% | 남은 시간: 41.25초\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 3.5ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.4ms\n",
      "Speed: 3.9ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 15.03% | 남은 시간: 40.62초\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 3.4ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.6ms\n",
      "Speed: 3.7ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 15.86% | 남은 시간: 40.07초\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 16.69% | 남은 시간: 39.60초\n",
      "\n",
      "0: 384x640 (no detections), 13.7ms\n",
      "Speed: 4.0ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.4ms\n",
      "Speed: 3.6ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 17.53% | 남은 시간: 38.96초\n",
      "\n",
      "0: 384x640 (no detections), 14.2ms\n",
      "Speed: 3.1ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 4.3ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 18.36% | 남은 시간: 38.35초\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.7ms preprocess, 16.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 19.20% | 남은 시간: 37.88초\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 5.8ms preprocess, 15.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.2ms\n",
      "Speed: 3.6ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 20.03% | 남은 시간: 37.28초\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 3.5ms preprocess, 15.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 20.87% | 남은 시간: 36.90초\n",
      "\n",
      "0: 384x640 (no detections), 17.9ms\n",
      "Speed: 4.6ms preprocess, 17.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 1 vase, 11.5ms\n",
      "Speed: 4.1ms preprocess, 11.5ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 21.70% | 남은 시간: 36.95초\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 1 vase, 12.3ms\n",
      "Speed: 4.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 1 vase, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 22.54% | 남은 시간: 36.96초\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 1 potted plant, 1 vase, 21.0ms\n",
      "Speed: 3.6ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 23.37% | 남은 시간: 36.92초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 13.0ms\n",
      "Speed: 3.3ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 potted plant, 1 vase, 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 24.21% | 남은 시간: 37.15초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 vase, 20.1ms\n",
      "Speed: 3.6ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 potted plant, 1 vase, 15.7ms\n",
      "Speed: 3.5ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 25.04% | 남은 시간: 37.85초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 potted plant, 2 vases, 20.8ms\n",
      "Speed: 3.4ms preprocess, 20.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 potted plant, 1 vase, 15.0ms\n",
      "Speed: 3.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 25.88% | 남은 시간: 38.55초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 potted plant, 1 vase, 17.9ms\n",
      "Speed: 4.4ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 32.4ms\n",
      "Speed: 4.7ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 26.71% | 남은 시간: 39.14초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 2 vases, 23.2ms\n",
      "Speed: 3.4ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 14.2ms\n",
      "Speed: 3.7ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 27.55% | 남은 시간: 39.36초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 10.3ms\n",
      "Speed: 4.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 13.8ms\n",
      "Speed: 3.9ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 28.38% | 남은 시간: 39.90초\n",
      "\n",
      "0: 384x640 2 persons, 1 couch, 1 potted plant, 1 vase, 13.3ms\n",
      "Speed: 3.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 1 potted plant, 2 vases, 13.4ms\n",
      "Speed: 4.2ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 29.22% | 남은 시간: 40.32초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 1 potted plant, 2 vases, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 2 vases, 11.1ms\n",
      "Speed: 7.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 30.05% | 남은 시간: 40.15초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 2 vases, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 2 chairs, 2 vases, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 30.88% | 남은 시간: 40.01초\n",
      "\n",
      "0: 384x640 2 persons, 1 bench, 1 chair, 1 couch, 2 vases, 13.4ms\n",
      "Speed: 3.6ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 2 vases, 10.7ms\n",
      "Speed: 3.5ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 31.72% | 남은 시간: 39.79초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 couch, 2 vases, 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 2 vases, 12.1ms\n",
      "Speed: 4.3ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 32.55% | 남은 시간: 39.54초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 2 vases, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 2 vases, 14.3ms\n",
      "Speed: 3.5ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 33.39% | 남은 시간: 39.22초\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 2 vases, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 2 vases, 11.0ms\n",
      "Speed: 3.3ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 34.22% | 남은 시간: 38.89초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 1 vase, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 2 vases, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 35.06% | 남은 시간: 38.51초\n",
      "\n",
      "0: 384x640 2 persons, 1 vase, 14.3ms\n",
      "Speed: 3.8ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 tv, 2 laptops, 13.5ms\n",
      "Speed: 3.4ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 35.89% | 남은 시간: 38.11초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 tv, 1 laptop, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 36.73% | 남은 시간: 37.90초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 12.1ms\n",
      "Speed: 5.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 37.56% | 남은 시간: 37.76초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 15.6ms\n",
      "Speed: 3.4ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 12.8ms\n",
      "Speed: 3.7ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 38.40% | 남은 시간: 37.56초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 14.6ms\n",
      "Speed: 3.2ms preprocess, 14.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 15.3ms\n",
      "Speed: 3.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 39.23% | 남은 시간: 37.35초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 11.1ms\n",
      "Speed: 3.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 40.07% | 남은 시간: 37.45초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 14.5ms\n",
      "Speed: 3.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 19.8ms\n",
      "Speed: 3.5ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 40.90% | 남은 시간: 38.02초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 tv, 27.2ms\n",
      "Speed: 7.5ms preprocess, 27.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 17.3ms\n",
      "Speed: 3.7ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 41.74% | 남은 시간: 38.39초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 12.9ms\n",
      "Speed: 3.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 11.4ms\n",
      "Speed: 3.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 42.57% | 남은 시간: 38.02초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 43.41% | 남은 시간: 37.66초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 13.0ms\n",
      "Speed: 3.4ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 44.24% | 남은 시간: 37.28초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 16.9ms\n",
      "Speed: 4.6ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 13.4ms\n",
      "Speed: 4.0ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 45.08% | 남은 시간: 36.90초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 12.1ms\n",
      "Speed: 3.4ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 15.2ms\n",
      "Speed: 4.3ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 45.91% | 남은 시간: 36.53초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 14.5ms\n",
      "Speed: 3.3ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 12.6ms\n",
      "Speed: 3.3ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 46.74% | 남은 시간: 36.13초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 14.0ms\n",
      "Speed: 4.2ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 13.3ms\n",
      "Speed: 4.5ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 47.58% | 남은 시간: 35.72초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 11.3ms\n",
      "Speed: 5.9ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 48.41% | 남은 시간: 35.32초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 16.1ms\n",
      "Speed: 3.2ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 17.2ms\n",
      "Speed: 4.2ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 49.25% | 남은 시간: 34.90초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 16.0ms\n",
      "Speed: 3.8ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 14.3ms\n",
      "Speed: 3.3ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 50.08% | 남은 시간: 34.47초\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 1 vase, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 50.92% | 남은 시간: 34.06초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 23.5ms\n",
      "Speed: 3.5ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 51.75% | 남은 시간: 33.65초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 15.2ms\n",
      "Speed: 7.2ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 11.5ms\n",
      "Speed: 3.5ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 52.59% | 남은 시간: 33.19초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 53.42% | 남은 시간: 32.69초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 19.8ms\n",
      "Speed: 3.6ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 26.1ms\n",
      "Speed: 7.0ms preprocess, 26.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 54.26% | 남은 시간: 32.50초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 13.8ms\n",
      "Speed: 3.4ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 29.1ms\n",
      "Speed: 3.4ms preprocess, 29.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 55.09% | 남은 시간: 32.27초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 25.4ms\n",
      "Speed: 6.2ms preprocess, 25.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 17.4ms\n",
      "Speed: 3.8ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 55.93% | 남은 시간: 32.00초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 16.0ms\n",
      "Speed: 4.3ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 14.1ms\n",
      "Speed: 3.5ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 56.76% | 남은 시간: 31.46초\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 16.2ms\n",
      "Speed: 4.0ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 12.7ms\n",
      "Speed: 3.8ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 57.60% | 남은 시간: 30.93초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 58.43% | 남은 시간: 30.41초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 15.0ms\n",
      "Speed: 3.2ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 59.27% | 남은 시간: 29.92초\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 15.4ms\n",
      "Speed: 3.5ms preprocess, 15.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 13.4ms\n",
      "Speed: 7.1ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 60.10% | 남은 시간: 29.44초\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 laptop, 12.2ms\n",
      "Speed: 3.2ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 60.93% | 남은 시간: 28.92초\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 18.1ms\n",
      "Speed: 3.4ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 13.4ms\n",
      "Speed: 3.5ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 61.77% | 남은 시간: 28.43초\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 1 laptop, 13.1ms\n",
      "Speed: 3.8ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.1ms\n",
      "Speed: 4.7ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 62.60% | 남은 시간: 27.86초\n",
      "\n",
      "0: 384x640 2 persons, 12.8ms\n",
      "Speed: 4.5ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 63.44% | 남은 시간: 27.21초\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 5.6ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 64.27% | 남은 시간: 26.56초\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.8ms\n",
      "Speed: 3.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 65.11% | 남은 시간: 25.91초\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 14.2ms\n",
      "Speed: 3.9ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.4ms\n",
      "Speed: 3.5ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 65.94% | 남은 시간: 25.27초\n",
      "\n",
      "0: 384x640 2 persons, 12.5ms\n",
      "Speed: 4.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.6ms\n",
      "Speed: 3.6ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 66.78% | 남은 시간: 24.64초\n",
      "\n",
      "0: 384x640 2 persons, 13.7ms\n",
      "Speed: 3.8ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.3ms\n",
      "Speed: 3.8ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 67.61% | 남은 시간: 24.02초\n",
      "\n",
      "0: 384x640 2 persons, 17.1ms\n",
      "Speed: 7.5ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.3ms\n",
      "Speed: 3.6ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 68.45% | 남은 시간: 23.45초\n",
      "\n",
      "0: 384x640 2 persons, 15.4ms\n",
      "Speed: 6.3ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.8ms\n",
      "Speed: 3.3ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 69.28% | 남은 시간: 22.94초\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 5.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 33.4ms\n",
      "Speed: 4.0ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 70.12% | 남은 시간: 22.43초\n",
      "\n",
      "0: 384x640 2 persons, 26.9ms\n",
      "Speed: 3.8ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 16.3ms\n",
      "Speed: 6.0ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 70.95% | 남은 시간: 21.91초\n",
      "\n",
      "0: 384x640 2 persons, 12.2ms\n",
      "Speed: 4.7ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.7ms\n",
      "Speed: 8.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 71.79% | 남은 시간: 21.26초\n",
      "\n",
      "0: 384x640 2 persons, 12.9ms\n",
      "Speed: 4.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.0ms\n",
      "Speed: 4.3ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 72.62% | 남은 시간: 20.61초\n",
      "\n",
      "0: 384x640 2 persons, 14.7ms\n",
      "Speed: 3.1ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 4.1ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 73.46% | 남은 시간: 19.96초\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 4.0ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.2ms\n",
      "Speed: 4.3ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 74.29% | 남은 시간: 19.33초\n",
      "\n",
      "0: 384x640 2 persons, 13.8ms\n",
      "Speed: 3.7ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.4ms\n",
      "Speed: 3.2ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 75.13% | 남은 시간: 18.69초\n",
      "\n",
      "0: 384x640 2 persons, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 75.96% | 남은 시간: 18.05초\n",
      "\n",
      "0: 384x640 2 persons, 13.2ms\n",
      "Speed: 4.0ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.9ms\n",
      "Speed: 3.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 76.79% | 남은 시간: 17.40초\n",
      "\n",
      "0: 384x640 2 persons, 17.4ms\n",
      "Speed: 3.5ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.4ms\n",
      "Speed: 3.2ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 77.63% | 남은 시간: 16.77초\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 78.46% | 남은 시간: 16.23초\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tie, 13.4ms\n",
      "Speed: 3.4ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 79.30% | 남은 시간: 15.66초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 17.1ms\n",
      "Speed: 4.8ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 80.13% | 남은 시간: 15.06초\n",
      "\n",
      "0: 384x640 3 persons, 14.4ms\n",
      "Speed: 4.8ms preprocess, 14.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.4ms\n",
      "Speed: 3.4ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 80.97% | 남은 시간: 14.47초\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 20.0ms\n",
      "Speed: 3.4ms preprocess, 20.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 dogs, 12.8ms\n",
      "Speed: 3.4ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 81.80% | 남은 시간: 13.94초\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 16.6ms\n",
      "Speed: 3.4ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 14.2ms\n",
      "Speed: 3.2ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 82.64% | 남은 시간: 13.38초\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 17.7ms\n",
      "Speed: 5.0ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 14.2ms\n",
      "Speed: 5.6ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 83.47% | 남은 시간: 12.91초\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 24.0ms\n",
      "Speed: 3.4ms preprocess, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 18.6ms\n",
      "Speed: 3.5ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 84.31% | 남은 시간: 12.40초\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 16.4ms\n",
      "Speed: 3.6ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 14.5ms\n",
      "Speed: 4.7ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 85.14% | 남은 시간: 11.77초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 15.2ms\n",
      "Speed: 4.4ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 85.98% | 남은 시간: 11.13초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.9ms\n",
      "Speed: 3.8ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 86.81% | 남은 시간: 10.48초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 13.9ms\n",
      "Speed: 3.9ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 87.65% | 남은 시간: 9.82초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 14.2ms\n",
      "Speed: 3.8ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 3.7ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 88.48% | 남은 시간: 9.16초\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 15.5ms\n",
      "Speed: 3.7ms preprocess, 15.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 13.9ms\n",
      "Speed: 3.3ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 89.32% | 남은 시간: 8.49초\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 10.7ms\n",
      "Speed: 3.5ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 90.15% | 남은 시간: 7.82초\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 19.3ms\n",
      "Speed: 4.6ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 90.98% | 남은 시간: 7.17초\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 13.0ms\n",
      "Speed: 3.2ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.7ms\n",
      "Speed: 4.2ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 91.82% | 남은 시간: 6.52초\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 11.6ms\n",
      "Speed: 4.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.6ms\n",
      "Speed: 4.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 92.65% | 남은 시간: 5.87초\n",
      "\n",
      "0: 384x640 3 persons, 11.1ms\n",
      "Speed: 3.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 93.49% | 남은 시간: 5.22초\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 94.32% | 남은 시간: 4.53초\n",
      "\n",
      "0: 384x640 3 persons, 11.4ms\n",
      "Speed: 3.7ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12.2ms\n",
      "Speed: 6.0ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 95.16% | 남은 시간: 3.87초\n",
      "\n",
      "0: 384x640 3 persons, 10.4ms\n",
      "Speed: 3.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.5ms\n",
      "Speed: 3.3ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 95.99% | 남은 시간: 3.22초\n",
      "\n",
      "0: 384x640 3 persons, 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16.1ms\n",
      "Speed: 3.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 96.83% | 남은 시간: 2.57초\n",
      "\n",
      "0: 384x640 3 persons, 26.0ms\n",
      "Speed: 4.5ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.0ms\n",
      "Speed: 3.2ms preprocess, 21.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 97.66% | 남은 시간: 1.91초\n",
      "\n",
      "0: 384x640 3 persons, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12.6ms\n",
      "Speed: 3.3ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 98.50% | 남은 시간: 1.23초\n",
      "\n",
      "0: 384x640 3 persons, 11.3ms\n",
      "Speed: 4.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "진행률: 99.33% | 남은 시간: 0.55초\n",
      "\n",
      "0: 384x640 3 persons, 24.2ms\n",
      "Speed: 3.2ms preprocess, 24.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "가명처리된 동영상이 저장되었습니다: /content/sample_data/blurred_output.mp4\n",
      "총 처리 시간: 81.81초\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_video_path = '/content/sample_data/sample.mp4'\n",
    "output_video_path = '/content/sample_data/blurred_output.mp4'\n",
    "\n",
    "# YOLOv8-Face 모델 로드 (GPU 사용 설정)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(\"/content/weights/yolov8n.pt\").to(device)\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 동영상의 속성 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# 비디오 저장 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# 시간 측정 시작\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "frame_skip = 5  # 프레임 샘플링 간격 (5 프레임마다 얼굴 재탐지)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임 샘플링: frame_skip 간격으로 얼굴 탐지 수행\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # YOLOv8-Face로 얼굴 탐지 (GPU에서 실행)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # RGB 변환 (필요 시)\n",
    "        results = model(frame_rgb)\n",
    "\n",
    "        # 얼굴 영역을 저장\n",
    "        faces = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy  # 얼굴 바운딩 박스 좌표 (x1, y1, x2, y2)\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)  # 정수형으로 변환\n",
    "                faces.append((x1, y1, x2, y2))  # 얼굴 위치 저장\n",
    "\n",
    "    # 이전에 저장된 얼굴 위치에 블러 처리\n",
    "    for (x1, y1, x2, y2) in faces:\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        blurred_face = cv2.GaussianBlur(face, (25, 25), 50)  # 강한 블러 적용\n",
    "        frame[y1:y2, x1:x2] = blurred_face\n",
    "\n",
    "    # 결과 프레임을 출력 파일에 저장\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # 남은 시간 예측\n",
    "    if frame_count % 10 == 0:  # 매 10 프레임마다 남은 시간 업데이트\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_total_time = (elapsed_time / frame_count) * total_frames\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "        print(f\"진행률: {frame_count / total_frames * 100:.2f}% | 남은 시간: {remaining_time:.2f}초\")\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 총 처리 시간\n",
    "end_time = time.time()\n",
    "total_elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"가명처리된 동영상이 저장되었습니다:\", output_video_path)\n",
    "print(f\"총 처리 시간: {total_elapsed_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrYWYLlZkV7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf04FiVjca6v",
    "outputId": "5a47803b-bac4-4900-f26d-4c3b9959fc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 2 persons, 1 tie, 82.0ms\n",
      "Speed: 2.2ms preprocess, 82.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "가명처리된 이미지가 저장되었습니다: /content/sample_data/blurred_output.jpg\n",
      "총 처리 시간: 0.21초\n"
     ]
    }
   ],
   "source": [
    "#2. 이미지 가명처리\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_image_path = '/content/sample_data/sample.jpg'\n",
    "output_image_path = '/content/sample_data/blurred_output.jpg'\n",
    "\n",
    "# YOLOv8 모델 로드 (GPU 사용 설정)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(\"/content/weights/yolov8n.pt\").to(device)\n",
    "\n",
    "# 이미지 파일 열기\n",
    "image = cv2.imread(input_image_path)\n",
    "if image is None:\n",
    "    print(\"이미지를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "else:\n",
    "    # 시간 측정 시작\n",
    "    start_time = time.time()\n",
    "\n",
    "    # YOLOv8으로 얼굴 탐지\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # YOLOv8은 RGB 포맷을 사용하므로 변환 필요\n",
    "    results = model(image_rgb)\n",
    "\n",
    "    # 얼굴 영역을 블러 처리\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy  # 얼굴 바운딩 박스 좌표 (x1, y1, x2, y2)\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)  # 정수형으로 변환\n",
    "            face = image[y1:y2, x1:x2]\n",
    "            blurred_face = cv2.GaussianBlur(face, (25, 25), 50)  # 강한 블러 적용\n",
    "            image[y1:y2, x1:x2] = blurred_face\n",
    "\n",
    "    # 처리 시간 측정 종료\n",
    "    end_time = time.time()\n",
    "    total_elapsed_time = end_time - start_time\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "    print(\"가명처리된 이미지가 저장되었습니다:\", output_image_path)\n",
    "    print(f\"총 처리 시간: {total_elapsed_time:.2f}초\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
